{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJH-mcs5q0Bu"
      },
      "outputs": [],
      "source": [
        "!pip install \"git+https://github.com/nixtla/neuralforecast.git@main\"\n",
        "!pip install darts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.losses.pytorch import MQLoss\n",
        "\n",
        "from datetime import date\n",
        "from darts import TimeSeries, concatenate\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.utils.statistics import check_seasonality, extract_trend_and_seasonality\n",
        "from darts.metrics import mape, rmse, mae, smape\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries, holidays_timeseries\n",
        "from darts.utils.likelihood_models import QuantileRegression"
      ],
      "metadata": {
        "id": "CrV_rSQeq6l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_df = pd.read_csv('Y_df.csv')\n",
        "\n",
        "Y_df['datetime'] = pd.to_datetime(Y_df['ds'])\n",
        "Y_df.drop('ds', axis=1, inplace=True)\n",
        "Y_df.set_index('datetime', inplace=True)\n",
        "series = TimeSeries.from_series(Y_df)\n",
        "\n",
        "series = series.add_datetime_attribute('hour')\n",
        "series = series.add_datetime_attribute('dayofweek')\n",
        "series = series.add_datetime_attribute('month')\n",
        "series = series.add_datetime_attribute('quarter')\n",
        "series = series.add_datetime_attribute('day')\n",
        "series = series.add_datetime_attribute('year')\n",
        "series = series.add_holidays(country_code='ITA')\n",
        "\n",
        "Y_df = TimeSeries.pd_dataframe(series).reset_index()\n",
        "Y_df.rename({'datetime': 'ds'}, axis=1, inplace=True)\n",
        "Y_df"
      ],
      "metadata": {
        "id": "Ba-55G96q6jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "Y_df.reset_index(inplace=True)\n",
        "def is_bridge_day(day, holiday, dayofweek):\n",
        "    if holiday == 1:\n",
        "        return 7\n",
        "    elif dayofweek in [5,6] and holiday == 0:\n",
        "        return dayofweek\n",
        "    elif dayofweek == 0 and holiday == 0 and Y_df.iloc[day+24]['holidays'] == 1:\n",
        "        return 8\n",
        "    elif dayofweek == 4 and holiday == 0 and Y_df.iloc[day-24]['holidays'] == 1:\n",
        "        return 8\n",
        "    else:\n",
        "        return dayofweek\n",
        "\n",
        "Y_df['day_of_week'] = np.vectorize(is_bridge_day)(Y_df.index, Y_df['holidays'], Y_df['dayofweek'])\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "calendar = ['hour', 'day', 'day_of_week', 'month', 'year']\n",
        "for cal in calendar:\n",
        "  Y_df[cal] = encoder.fit_transform(Y_df[cal]).astype(np.int32)\n",
        "Y_df"
      ],
      "metadata": {
        "id": "VlQoZwkGq6hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size  = 190*24\n",
        "test_size = 190*24\n",
        "Y_train_df = Y_df.iloc[:-test_size, :]\n",
        "Y_test_df = Y_df.iloc[-test_size:, :]\n",
        "Y_val_df = Y_train_df.iloc[-val_size:, :]"
      ],
      "metadata": {
        "id": "-HOXZGxFq6es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the plot\n",
        "import matplotlib\n",
        "matplotlib.rc_file_defaults()\n",
        "\n",
        "# Create subplots with two rows\n",
        "fig, axs = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
        "\n",
        "# Plot the load data in the first subplot\n",
        "axs[0].plot(Y_train_df['ds'], Y_train_df['y'], color='steelblue', label='Electricity Price')\n",
        "axs[0].plot(Y_val_df['ds'], Y_val_df['y'], color='steelblue')\n",
        "axs[0].plot(Y_test_df['ds'], Y_test_df['y'], color='steelblue')\n",
        "axs[0].set_ylabel('Spot Price (€/MWh)', fontsize=12)\n",
        "axs[0].legend(loc = \"upper left\")\n",
        "legend = axs[0].get_legend()\n",
        "\n",
        "# Set the font size of the legend\n",
        "legend.get_frame().set_facecolor('white')  # Optional: Set legend background color\n",
        "legend.get_frame().set_linewidth(0.5)  # Optional: Set legend frame linewidth\n",
        "for text in legend.get_texts():\n",
        "    text.set_fontsize(12)  # Set the font size\n",
        "\n",
        "\n",
        "# Plot the temperature data in the second subplot\n",
        "axs[1].plot(Y_train_df['ds'], Y_train_df['psvda'], color='seagreen', label='PSVDA')\n",
        "axs[1].plot(Y_val_df['ds'], Y_val_df['psvda'], color='seagreen')\n",
        "axs[1].plot(Y_test_df['ds'], Y_test_df['psvda'], color='seagreen')\n",
        "axs[1].set_ylabel('PSV day-ahead (€/MWh)', fontsize=12)\n",
        "axs[1].legend(loc=\"upper left\")\n",
        "# Get the current legend\n",
        "legend_1 = axs[1].get_legend()\n",
        "\n",
        "# Set the font size of the legend\n",
        "legend_1.get_frame().set_facecolor('white')  # Optional: Set legend background color\n",
        "legend_1.get_frame().set_linewidth(0.5)  # Optional: Set legend frame linewidth\n",
        "for text in legend_1.get_texts():\n",
        "    text.set_fontsize(12)  # Set the font size\n",
        "\n",
        "# Plot the temperature data in the second subplot\n",
        "axs[2].plot(Y_train_df['ds'], Y_train_df['load forecast'], color='lightcoral', label='Load Forecast')\n",
        "axs[2].plot(Y_val_df['ds'], Y_val_df['load forecast'], color='lightcoral')\n",
        "axs[2].plot(Y_test_df['ds'], Y_test_df['load forecast'], color='lightcoral')\n",
        "axs[2].set_ylabel('Load (MW)', fontsize=12)\n",
        "axs[2].legend(loc=\"upper left\")\n",
        "# Get the current legend\n",
        "legend_2 = axs[2].get_legend()\n",
        "\n",
        "# Set the font size of the legend\n",
        "legend_2.get_frame().set_facecolor('white')  # Optional: Set legend background color\n",
        "legend_2.get_frame().set_linewidth(0.5)  # Optional: Set legend frame linewidth\n",
        "for text in legend_2.get_texts():\n",
        "    text.set_fontsize(12)  # Set the font size\n",
        "\n",
        "\n",
        "# Add annotations for the splits\n",
        "axs[0].annotate('Training', xy=(Y_train_df['ds'].mean(), Y_train_df['y'].max()), xytext=(0, 20),\n",
        "             xycoords='data', textcoords='offset points', fontsize=15, ha='center')\n",
        "axs[0].annotate('Validation', xy=(Y_val_df['ds'].mean(), Y_train_df['y'].max()), xytext=(0, 20),\n",
        "             xycoords='data', textcoords='offset points', fontsize=15, ha='center')\n",
        "axs[0].annotate('Test', xy=(Y_test_df['ds'].mean(), Y_train_df['y'].max()), xytext=(0, 20),\n",
        "             xycoords='data', textcoords='offset points', fontsize=15, ha='center')\n",
        "\n",
        "# Add dashed lines for the splits\n",
        "axs[0].axvline(Y_val_df['ds'].iloc[0], color='k', linestyle='--')\n",
        "axs[0].axvline(Y_val_df['ds'].iloc[-1], color='k', linestyle='--')\n",
        "axs[1].axvline(Y_val_df['ds'].iloc[0], color='k', linestyle='--')  # Shared vertical line\n",
        "axs[1].axvline(Y_val_df['ds'].iloc[-1], color='k', linestyle='--')\n",
        "axs[2].axvline(Y_val_df['ds'].iloc[0], color='k', linestyle='--')  # Shared vertical line\n",
        "axs[2].axvline(Y_val_df['ds'].iloc[-1], color='k', linestyle='--')\n",
        "\n",
        "plt.xlabel('Datetime', fontsize=12)\n",
        "#plt.suptitle('Electricity Demand', fontsize=15)\n",
        "plt.subplots_adjust(hspace=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0TZDaM_urvLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a copy of Y_train_df\n",
        "df_train = Y_train_df.copy()\n",
        "\n",
        "# Map quarter labels to the \"Quarter\" column\n",
        "quarter_labels = {1: 'Q1', 2: 'Q2', 3: 'Q3', 4: 'Q4'}\n",
        "df_train['Quarter'] = df_train['quarter'].map(quarter_labels)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.lineplot(data=df_train, x='hour', y='y', hue='Quarter', palette=palette, linewidth=3)\n",
        "\n",
        "# Remove the spines\n",
        "sns.despine()\n",
        "\n",
        "# Set the title\n",
        "plt.ylabel('Price (€/MWh)')\n",
        "\n",
        "# Change the legend labels\n",
        "legend = plt.legend(fontsize='large')\n",
        "for line, label in zip(legend.get_lines(), quarter_labels.values()):\n",
        "    line.set_linewidth(3.0)\n",
        "    line.set_label(label)\n",
        "plt.grid(False)\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ji3CkoFarvnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralforecast.losses.pytorch import MQLoss\n",
        "from neuralforecast.auto import AutoNBEATSx\n",
        "from ray import tune\n",
        "horizon=24\n",
        "levels=[80,90]\n",
        "# Use your own config or AutoLSTM.default_config\n",
        "nbeats_config = {\n",
        "       \"futr_exog_list\" : tune.choice([['hour', 'dayofweek', 'month', 'quarter', 'holidays', 'day', 'year'],\n",
        "                                       ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'dayofweek_sin', 'dayofweek_cos',\n",
        "                                        'month_sin', 'month_cos', 'quarter_sin', 'quarter_cos', 'year', 'holidays']]),\n",
        "       \"learning_rate\": tune.choice([1e-3, 1e-4]),\n",
        "       \"max_steps\": tune.choice([100, 200, 400]),\n",
        "       \"input_size\": tune.choice([5*horizon, 7*horizon, 2*horizon]),\n",
        "       \"batch_size\": tune.choice([32, 64]),\n",
        "       \"activation\": tune.choice(['ReLU']),\n",
        "       \"n_blocks\":  tune.choice([[1, 2, 3], [1, 1, 1]]),\n",
        "       \"mlp_units\":  tune.choice([[[512, 512], [512, 512], [512, 512]]]),\n",
        "       \"val_check_steps\": tune.choice([20]),\n",
        "       \"random_seed\": tune.randint(1, 10),\n",
        "       \"scaler_type\": tune.choice(['minmax', 'robust'])\n",
        "    }\n",
        "\n",
        "\n",
        "model_nbeats = [AutoNBEATSx(h=horizon,\n",
        "                   config=nbeats_config,\n",
        "                   loss=MQLoss(level=levels),\n",
        "                   num_samples=10,\n",
        "                   verbose=True,\n",
        "                   refit_with_val=True)]"
      ],
      "metadata": {
        "id": "1IL3ltT0r3N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nf = NeuralForecast(models=model_nbeats, freq='H')\n",
        "fcst_df = nf.fit(Y_train_df, val_size=val_size, verbose=True)"
      ],
      "metadata": {
        "id": "JRDmkCGOsEML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralforecast.models import NBEATSx\n",
        "from neuralforecast.losses.pytorch import MQLoss\n",
        "from neuralforecast.auto import AutoNBEATSx\n",
        "from ray import tune\n",
        "levels = [90]\n",
        "model_nbeats = NBEATSx(h=24,\n",
        "            input_size=168,\n",
        "            learning_rate=0.001,\n",
        "            max_steps=400,\n",
        "            val_check_steps=20,\n",
        "            loss=MQLoss(level=levels),\n",
        "            batch_size=64,\n",
        "            activation = 'ReLU',\n",
        "            n_blocks = [1, 1, 1],\n",
        "            mlp_units = [[512, 512], [512, 512], [512, 512]],\n",
        "            random_seed = 3,\n",
        "            scaler_type = 'minmax',\n",
        "            futr_exog_list =['hour', 'day_of_week', 'month',  'day', 'year', 'load forecast'],\n",
        "            hist_exog_list = ['psvda'])\n",
        "\n",
        "fcst = NeuralForecast(\n",
        "    models=[model_nbeats],\n",
        "    freq='H'\n",
        ")\n",
        "fcst.fit(Y_train_df, verbose=True)"
      ],
      "metadata": {
        "id": "T7L10ZvbsKf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_df['dayofweek'] = Y_df['dayofweek'].astype('float32')\n",
        "Y_test_df['date'] = [x[:11] for x in Y_test_df.ds.astype('str')]\n",
        "Y_df['date'] = [x[:11] for x in Y_df.ds.astype('str')]"
      ],
      "metadata": {
        "id": "6BJlUI3SsOkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_df_nbeats = pd.DataFrame()\n",
        "for day in Y_test_df['date'].drop_duplicates():\n",
        "    df_futr = Y_df[Y_df['date'] == day]\n",
        "    df_test = Y_df[Y_df['date'] < day].tail(len(Y_train_df)) # the size of training df remain the same\n",
        "    check_fit = df_futr.iloc[:1, :]['dayofweek'].values[0]\n",
        "    #if check_fit == 3.0:\n",
        "       #fcst.fit(df_test.drop('date', axis=1), verbose=True)\n",
        "    Y_hat = fcst.predict(df=df_test.drop('date', axis=1), futr_df=df_futr.drop('date', axis=1))\n",
        "    Y_hat_df_nbeats = pd.concat([Y_hat_df_nbeats, Y_hat], axis=0)\n",
        "Y_hat_df_nbeats"
      ],
      "metadata": {
        "id": "We2DvTqosQEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralforecast.losses.numpy import mae, mape\n",
        "Y_hat_df_nbeats['ds'] = pd.to_datetime(Y_hat_df_nbeats['ds'])\n",
        "Y_hat_df_nbeats.columns = Y_hat_df_nbeats.columns.str.replace('-median', '')\n",
        "plot_df_nbeats = Y_test_df.merge(Y_hat_df_nbeats, on=['unique_id','ds'], how='inner')\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(plot_df_nbeats['ds'], plot_df_nbeats['y'], c='black', label='True')\n",
        "plt.plot(plot_df_nbeats['ds'], plot_df_nbeats['NBEATSx'], c='steelblue', label='Forecast')\n",
        "#plt.axvline(pd.to_datetime('2022-12-24'), color='red', linestyle='-.')\n",
        "plt.fill_between(x=plot_df_nbeats['ds'],\n",
        "                    y1=plot_df_nbeats['NBEATSx-lo-90'], y2=plot_df_nbeats['NBEATSx-hi-90'],\n",
        "                    alpha=0.4, label='level 90', color='steelblue')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.plot()\n",
        "\n",
        "print('MAE: ', mae(plot_df_nbeats['y'], plot_df_nbeats['NBEATSx']))\n",
        "print('MAPE: ', mape(plot_df_nbeats['y'], plot_df_nbeats['NBEATSx']))"
      ],
      "metadata": {
        "id": "l8MsQQpisSQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
