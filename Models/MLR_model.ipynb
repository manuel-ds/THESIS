{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaWTPXz6XPG1"
      },
      "outputs": [],
      "source": [
        "!pip install darts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from darts import TimeSeries, concatenate"
      ],
      "metadata": {
        "id": "r1MF9vIiXTXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_df = pd.read_csv('df_load.csv')"
      ],
      "metadata": {
        "id": "ZeUjxyu3YNis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_df['datetime'] = pd.to_datetime(Y_df['ds'])\n",
        "Y_df.drop('ds', axis=1, inplace=True)\n",
        "Y_df.set_index('datetime', inplace=True)\n",
        "series = TimeSeries.from_series(Y_df)\n",
        "\n",
        "# create calendar variables features\n",
        "series = series.add_datetime_attribute('hour')\n",
        "series = series.add_datetime_attribute('dayofweek')\n",
        "series = series.add_datetime_attribute('month')\n",
        "series = series.add_datetime_attribute('quarter')\n",
        "series = series.add_datetime_attribute('day')\n",
        "series = series.add_datetime_attribute('year')\n",
        "series = series.add_holidays(country_code='ITA') #holidays"
      ],
      "metadata": {
        "id": "Tv9WlWsf1S-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#linear trend\n",
        "Y_df['linear_trend'] = range(1, len(Y_df) + 1)\n",
        "\n",
        "# week*hour variable\n",
        "Y_df['weho'] = Y_df['hour'] * Y_df['dayofweek']\n",
        "\n",
        "# Perform one-hot encoding\n",
        "data_encoded = pd.get_dummies(Y_df, columns=['dayofweek', 'hour', 'month', 'weho'], drop_first=True)\n",
        "\n",
        "# polynomial terms for temperatures\n",
        "data_encoded['temperature_squared'] = data_encoded['temperature_2m_rom'] ** 2\n",
        "data_encoded['temperature_cubed'] = data_encoded['temperature_2m_rom'] ** 3\n",
        "\n",
        "# Iterate over each month column\n",
        "for month_col in data_encoded.filter(like='month_').columns:\n",
        "    data_encoded[month_col + '_temperature'] = data_encoded[month_col] * data_encoded['temperature_2m_rom']\n",
        "\n",
        "# Create interaction terms between hour and temperatures\n",
        "for hour_col in data_encoded.filter(like='hour_').columns:\n",
        "        data_encoded[hour_col + '_temperature'] = data_encoded[hour_col] * data_encoded['temperature_2m_rom']\n",
        "\n",
        "for hour_col in data_encoded.filter(like='hour_').columns:\n",
        "        data_encoded[hour_col + '_temperature'] = data_encoded[hour_col] * data_encoded['temperature_2m_rom']\n",
        "\n",
        "\n",
        "\n",
        "#Concatenate the features\n",
        "X = data_encoded[['linear_trend','temperature_2m_rom', 'temperature_squared', 'temperature_cubed'] +\n",
        "                data_encoded.filter(like='month_').columns.tolist() +\n",
        "                 data_encoded.filter(like='hour_').columns.tolist() +\n",
        "                 data_encoded.filter(like='weho_').columns.tolist()]\n",
        "\n",
        "\n",
        "y_df = pd.concat([Y_df['y'], X], axis=1)"
      ],
      "metadata": {
        "id": "dcyDFbM7AjyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test and validation indexes\n",
        "test_index = len(y_df) - 365*24\n",
        "validation_index = test_index - 365*24\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "Y_train_df = y_df.iloc[:validation_index]\n",
        "Y_val_df = y_df.iloc[validation_index:test_index]\n",
        "Y_test_df = y_df.iloc[test_index:]\n",
        "Y_trainval_df = y_df.iloc[:test_index, :]"
      ],
      "metadata": {
        "id": "Qo373ohdAxHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = Y_train_df.drop('y', axis=1)\n",
        "X_val = Y_val_df.drop('y', axis=1)\n",
        "X_test = Y_test_df.drop('y', axis=1)\n",
        "X_trainval = Y_trainval_df.drop('y', axis=1)\n",
        "\n",
        "y_train = Y_train_df['y']\n",
        "y_val = Y_val_df['y']\n",
        "y_test = Y_test_df['y']\n",
        "y_trainval = Y_trainval_df['y']"
      ],
      "metadata": {
        "id": "fvrKNZDPAyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the regression model on the training set\n",
        "reg_model = LinearRegression()\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# predict the validation set\n",
        "preds_val = reg_model.predict(X_val)\n",
        "preds_df_val = pd.DataFrame(preds_val, columns=['prediction'], index=Y_val_df.index)\n",
        "validation_df = pd.concat([Y_val_df['y'], preds_df_val], axis=1)\n",
        "validation_df.rename({'y': 'actual'}, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "QSBG3wRUAyQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the regression model on the trainval set\n",
        "reg_model = LinearRegression()\n",
        "reg_model.fit(X_trainval, y_trainval)\n",
        "\n",
        "# predict the test set\n",
        "preds_test = reg_model.predict(X_test)\n",
        "preds_df_test = pd.DataFrame(preds_test, columns=['pred_q2'], index=Y_test_df.index)\n",
        "test_df = pd.concat([Y_test_df['y'], preds_df_test], axis=1)\n",
        "test_df.rename({'y': 'actual'}, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Wcb8YfSlCGK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate residuals\n",
        "def calculate_residuals(predictions, true_values):\n",
        "    return true_values - predictions\n",
        "\n",
        "# Function to perform empirical bootstrap\n",
        "def empirical_bootstrap(validation_df, test_predictions, num_bootstrap_samples, confidence_level):\n",
        "    np.random.seed(42)  # Set random seed for reproducibility\n",
        "\n",
        "    # compute residuals distribution on validation set\n",
        "    validation_residuals = calculate_residuals(validation_df['prediction'], validation_df['actual'])\n",
        "\n",
        "    bootstrap_predictions = []\n",
        "    num_samples = len(test_predictions)\n",
        "\n",
        "    for _ in range(num_bootstrap_samples):\n",
        "        bootstrap_residuals = np.random.choice(validation_residuals, size=num_samples, replace=True)\n",
        "        bootstrap_predictions.append(test_predictions + bootstrap_residuals)\n",
        "\n",
        "    # Calculate confidence intervals\n",
        "    lower_quantile = (1 - confidence_level) / 2\n",
        "    upper_quantile = 1 - lower_quantile\n",
        "    lower_bound = np.percentile(bootstrap_predictions, lower_quantile * 100, axis=0)\n",
        "    upper_bound = np.percentile(bootstrap_predictions, upper_quantile * 100, axis=0)\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Define the number of bootstrap samples and the desired confidence level\n",
        "num_bootstrap_samples = 1000\n",
        "confidence_level = 0.80\n",
        "\n",
        "\n",
        "test_predictions = test_df['MLR_q2']\n",
        "\n",
        "# Call the empirical_bootstrap function\n",
        "lower_bound, upper_bound = empirical_bootstrap(validation_df, test_predictions, num_bootstrap_samples, confidence_level)\n",
        "\n",
        "test_df['MLR_q1'] = lower_bound #10th quantile\n",
        "test_df['MLR_q3'] = upper_bound #90th quantile"
      ],
      "metadata": {
        "id": "4ZDzRy4iA8H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predictions\n",
        "test_df.to_csv('MLR_predictions.csv')"
      ],
      "metadata": {
        "id": "UP_BJJxDA8E0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
